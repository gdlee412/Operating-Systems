# Scheduling Basics
## Vocabulary
- Workload: set of job descriptions (arrival time, run_time)    
    - Job: View as current CPU burst of a process
    - Arrival time: When the jobs will arrive and begin
    - Run time: the time a job takes to process
    - Process alternates between CPU and I/O works
        - Process moves between ready and blocked queues
- Scheduler: logic that decides which ready job to run
- Metric: measurement of scheduling quality

## Scheduling: Introduction
- Workload assumptions
    1. Each job runs for the **same amount of time**
    2. All jobs **arrive** at the same time
    3. All jobs only use the **CPU** (i.e., they perform no I/O)
    4. The **run-time** of each job is known

## Scheduling Metrics
- Performance metric: ``Turnaround time``
    - The time at which **the job completes** minus the time at which **the job arrived** in the system

$$T_{turnaround} = T_{completion} - T_{arrival}$$

- Another metric is ``fairness``
    - Performance and fairness are often at odds in scheduling

## First In, First Out (FIFO)
- First Come, First Served (FCFS)
    - Very simple and easy to implement
- Example:
    - A arrived just before B which arrived just before C
    - Each job runs for 10 secs
- Gantt chart: Illustrates how jobs are scheduled over time on a CPU

$$Average turnaround time = \frac{10 + 20 + 30}{3} = 20 sec$$

### Cons: *Convoy effect*
- `Head of Line Delay (HOLD)`
- Let's relax assumption 1
    - Now each job **no longer** runs for the same amount of time
- Example:
    - A arrived just before B which arrived just before C
    - A runs for 100 seconds, B and C run for 10 each

$$Average'turnaround'time = \frac{100 + 110 + 120}{3} = 110 sec$$

## Passing the Tractor: Shortest Job First (SJF)
- Run the shortest job first, then the next shortest, and so on
    - Non-preemptive scheduling
- Example:
    - A arrived just before B which arrived just before C
    - A runs for 100 seconds, B and C run for 10 each.

$$Average'turnaround'time = \frac{10 + 20 + 120}{3} = 50 sec$$

### SJF with Late Arrivals from B and C
- Let's relax assumption 2: Jobs can arrive at any time
- Example
    - A arrives at t=0 and needs to run for 100secs
    - B and C arrive at t=10 and each need to run for 10 sec

$$Average turnaround time = \frac{100 + (110-10) + (120-10)}{3} = 103.33 sec$$

## Preemptive Scheduling
- Prev schedulers
    - FIFO and SJF are non-preemptive
    - only schedule new job when previous job voluntarily relinquishes CPU (performs I/O or exits)
- New scheduler
    - Preemptive: Potentially schedule different job at any point by taking CPU away from running job
    - STCF (Shortest Time-to-Completion First)
    - Always run job that will complete the quickest

### Shortest Time-to Completion First (STCF)
- Add preemption to SJF
    - also known as Preemptive Shortest job first (PSJF)
- A new job enters the system
    - determine of the remaining jobs and new job
    - schedule the job which has the lest time left

- Example
    - A arrives at t=0 and needs to run for 100 seconds
    - B and C arrive at t=10 and each run for 10 seconds

$$Average'turnaround'time = \frac{(120 - 0) + (20-10) + (30-10)}{3} = 50 sec$$

## New Scheduling metric: Response time
- the time from when the job arrives to the first time is scheduled
$$T_{response} = T_{firstrun} - T_{arrival}$$
- STCF and related disciplines are not particularly good for response time
- How can we build a scheduler that is **sensitive to response time**?

## Round Robin (RR) Scheduling
- Time Slicing Scheduling
    - run a job for a **time slice** and then switch to the next job in the **run queue** until the jobs are finished
        - Time slice is sometimes called a <u>scheduling quantum</u>
    - It repeatedly does so until the jobs are finished
    - The length of a time slice must be a *multiple of* the timer-interrupt period

```
RR is fair, but performs poorly on metrics such as turnaround time
```

- Example
    - A, B, and C arrive at the same time
    - They each wish to run for 5 seconds

SJF
$$T_{average response} = \frac{0 + 5 + 10}{3} = 5 sec$$

RR with a time slice of 1 sec(Good for response time)
$$T_{average response} = \frac{0 + 1 + 2}{3} = 1 sec$$

### Length of a Time slice
- the shorter time slice
    - better response time
    - cost of context switching will dominate overall performance
- the longer time slice
    - amortize the cost of switching
    - worse response time

```
Deciding on the length of the time slice presents a trade-off to a system designer
```
``May come out in the exam``
```
Important
```
## Incorporating I/O
- Let's relax assumption 3
    - All programs perform I/O
- Example
    - A and B need 50ms of CPU time each
    - A runs for 10ms and then issues an I/O request
        - I/Os each take 10ms
    - B simply uses the CPU for 40ms and performs no I/O
    - The scheduler runs A first, then B after

- Overlap allows better use of resources & maximizes the CPu utilization

- When a job initiates an I/O request
    - the job is blocked waiting for I/O completion
    - the scheduler should schedule another job on the CPU
- When the I/O completes
    - an interrupt is raised
    - the OS moves the process from blocked back to the ready state

## Multi-Level Feedback Queue (MLFQ)
- A scheduler that learns from the past to predict the future
- Objective:
    - optimize **turnaround time**: run shorter jobs first
    - minimize **response time** without a *prior knowledge of job length*

### MLFQ: Basic Rules
- MLFQ has a number of distinct **queues**
    - each queues is assigned a different priority level
- A job that is ready to run is on a single queue
    - a job **on a higher queue** is chosen to run
    - Use RR scheduling among jobs in the same queue

```
Rule 1: If Priority(A) > Priority(B), A runs (B doesn't)

Rule 2: If Priority(A) = Priority(B), A & B run in RR
```
- MLFQ varies the priority of a job based on its observed behavior
- yield();
    - one of the first system calls
    - yield the CPU back to the OS
- Example
    - A job repeatedly relinquishes the CPU while waiting IOs -> Keep priority high
        - Since there's a high chance these are interactive programs that will continuously request I/O
    - A job uses the CPU intensively for long  periods of time -> Reduce its priority

### MLFQ: How to Change Priority
- MLFQ priority adjustment algorithm
    - Rule 3: When a job enters the system, it is placed at the highest priority
    - Rule 4a: If a job uses up an entire time slice while running, its priority is reduced (i.e., it moves down on queue)
    - Rule 4b: If a job gives up the CPU before the time slice is up, it stays at the same priority level

```
In this manner, MLFQ approximates SJF
```

```
Problem 1: No way of increasing Priority
```
```
Problem 2: Time slice is unnecessarily short for low priority queues which need better turnaround time

Solution: Increase the Time slice the lower the priority
```

### Example 1: a single long-running job
- A three-queue scheduler with time slice 10ms

### Example 2: Along came a short job
- Assumption
    - Job A: a long-running CPU-intensive job
    - Job B: A short-running interactive job (20ms runtime)
    - A has been running for some time, and then B arrives at time T=100
        - switches and runs B

### Example 3: What about I/O?
- Assumption
    - Job A: a long-running CPU-intensive job
    - Job B: An interactive job that need the CPU only for 1ms before performing an I/O
```
The MLFQ approach keeps an interactive job at the highest priority
```

### Problems with the Basic MLFQ
- ``Starvation``
``Will be mentioned a lot in OS ``
    - If there are "too many" interactive jobs in the system
    - long-running jobs `(batch)` will never receive any CPU time
        - no guarantee for progress
- Game the scheduler
    - After running 99% of a time slice, issue an I/O operation
    - The job gain a higher percentage of CPU time
- A program may change its behavior over time
    - CPU bound process -> I/O bound process
    - no method to increase priority

### Priority Boost
- Rule 5: After some time period S, move all the jobs in the system to the topmost queue

- Example
    - a long-running job(A) with two short-running interactive job (B, C)

### Better Accounting
- How to prevent gaming of our scheduler?
- Solution
    - Rule 4 (rewrite Rules 4a and 4b): ONce a job **uses up its time allotment** at a given level (regardless of how many times it has given up the CPU), **its priority is reduced** (i.e., it moves down on queue)

- time slice: used for round robin scheduling
- time allotment: used to change priority as stated in Rule 4

### Turning MLFQ and Other Issues
``Lower Priority, Longer Quanta``

- The high-priority queues -> Short time slices
    - e.g., 10 or fewer milliseconds
- The low-priority queue -> Longer time slices
    - e.g., 100 milliseconds


### The Solaris MLFQ implementation
- For the Time-Sharing scheduling class (TS)
    - 60 queues
    - slowly increasing time-slice length
        - the highest priority: 20ms
        - The lowest priority: a few hundred ms
    - Priorities boosted around every 1 second or so

### MLFQ: Summary
#### The refined set of MLFQ rules:
- Rule 1: If Priority(A) > Priority(B), A runs (B doesn't)
- Rule 2: If Priority(A) = Priority(B), A & B run in RR
- Rule 3: When a job enters the system, it is placed at the highest priority
- Rule 4: Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down on queue)
- Rule 5: After some time period S, move all the jobs in the system to the topmost queue


## Fun Fact
- Real-time system
    - when programs interact with real time conditions
- Hard Real-time
    - Real time consideration is critical and essential
    - e.g., Planes, missile systems, etc

- Soft real-time
    - emulates real time systems, but not necessarily important
    - e.g., games